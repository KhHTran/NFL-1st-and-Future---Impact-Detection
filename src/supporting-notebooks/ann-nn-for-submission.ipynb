{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = torch.load('../input/nfltrainimagecrop/train_ds_no_mask_crops.pt')\ny_train = torch.load('../input/nfltrainimagecrop/train_ds_no_mask_labels.pt').type(torch.LongTensor)\nX_test = torch.load('../input/nfltrainimagecrop/test_ds_no_mask_crops.pt')\ny_test = torch.load('../input/nfltrainimagecrop/test_ds_no_mask_labels.pt').type(torch.LongTensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\nclass Dataset(torch.utils.data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, X, y, transform=None):\n        'Initialization'\n        self.X = X\n        self.y = y\n        self.transform = transform\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.y)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        X = self.X[index]\n        y = self.y[index]\n        X = self.transform(X)\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.Resize((32,32)),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = Dataset(X_train, y_train,transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = Dataset(X_test, y_test,transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('no-impact','impact')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[int(labels[j])] for j in range(4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 32)\n        self.fc4 = nn.Linear(32, 2)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n\nnet = Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(20):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n#         if (i % 100 == 99) and (epoch % 5 == 4):    # print every 2000 mini-batches\n        if (i % 100 == 99) :    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = './classifier_net.pth'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[int(labels[j])] for j in range(4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\nnet.load_state_dict(torch.load(PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = net(images)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\ny_pred = []\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        y_pred += predicted\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.metrics import classification_report\nprint(classification_report(y_test,np.array(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test.numpy(), np.array(y_pred))\n\ncm_display = ConfusionMatrixDisplay(cm).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reload the saved dataset.\ndf_submission = pd.read_csv('../input/nlfimpactdfsubmission/template_submission.csv')\ndf_submission['video'] = df_submission['video'] + '.mp4'\ndel df_submission['Unnamed: 0']\ndf_submission.reset_index(inplace = True)\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictor(X, index):\n    X = transform(X)\n    outputs = net(X)\n    _, predicted = torch.max(outputs.data, 1)\n    return pd.Series(predicted, index=index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_0.pt')\ndf_submission.loc[:10000-1,'impact'] = predictor(_data, index=df_submission.loc[:10000-1,'index'])\n\n_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_1.pt')\ndf_submission.loc[10000:20000-1,'impact'] = predictor(_data, index=df_submission.loc[10000:20000-1,'index'])\n\n_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_2.pt')\ndf_submission.loc[20000:30000-1,'impact'] = predictor(_data, index=df_submission.loc[20000:30000-1,'index'])\n\n_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_3.pt')\ndf_submission.loc[30000:40000-1,'impact'] = predictor(_data, index=df_submission.loc[30000:40000-1,'index'])\n\n_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_4.pt')\ndf_submission.loc[40000:50000-1,'impact'] = predictor(_data, index=df_submission.loc[40000:50000-1,'index'])\n\n_data = torch.load('../input/crop-for-submission/submission_imgs_no_mask_crops_5.pt')\ndf_submission.loc[50000:,'impact'] =  predictor(_data, index=df_submission.loc[50000:,'index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv()\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(df_submission['impact'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission_impact = df_submission.loc[df_submission['impact']==1,['gameKey','playID','view','video','frame','left','width','top','height']]\ndf_submission_impact['left'] =df_submission_impact['left'].astype(int)\ndf_submission_impact['width'] =df_submission_impact['width'].astype(int)\ndf_submission_impact['top'] =df_submission_impact['top'].astype(int)\ndf_submission_impact['height'] =df_submission_impact['height'].astype(int)\ndf_submission_impact.reset_index(inplace=True, drop=True)\n\ndf_submission_impact.to_csv()\ndf_submission_impact","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nflimpact\nenv = nflimpact.make_env()\nenv.predict(df_submission_impact) # df is a pandas dataframe of your entire submission file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(_data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv('./submission.csv').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}