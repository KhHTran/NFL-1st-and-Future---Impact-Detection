{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[K     |████████████████████████████████| 58 kB 822 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.8.1)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (3.7.4.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.5)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.7.0)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (8.0.1)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=39a8a72f8ea3ac8626e4b350c38b5283d4f60f16c4248a645f02e8f4438d7dea\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built pretrainedmodels\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pretrainedmodels\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pair_list_test = [(57583, 82), (57586, 4152), (57680, 2206)]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm \nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torch\nimport torchvision.models as models\n\nimport albumentations as A\n# from albumentations.pytorch.transforms import ToTensor, ToTensorV2\n# from albumentations.augmentations.transforms import Normalize\n\nfrom albumentations import Compose, RandomCrop, Normalize, HorizontalFlip, Resize\nfrom albumentations.pytorch import ToTensor","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"! ls ../input/resnet18-on-bboxes","execution_count":6,"outputs":[{"output_type":"stream","text":"__notebook__.ipynb  big_helmet_test.csv   helmet_crop_train\r\n__output__.json     big_helmet_train.csv  well_test_dataset.csv\r\n__results__.html    custom.css\t\t  well_train_dataset.csv\r\n__results___files   helmet_crop_test\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_name(row):\n#     print(row)\n    input_name = row.image_name\n    playerLabel = row.label\n    impact = row.impact\n    return f\"{input_name[:-4]}_{playerLabel}_{int(impact)}.png\"\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/resnet18-on-bboxes/well_train_dataset.csv')\ntest_df = pd.read_csv('../input/resnet18-on-bboxes/well_test_dataset.csv')\n\ntrain_df['image_name'] = train_df.apply(lambda x: convert_name(x), axis=1)\ntest_df['image_name'] = test_df.apply(lambda x: convert_name(x), axis=1)\n\ntrain_df.to_csv('well_train_dataset.csv')\ntest_df.to_csv('well_test_dataset.csv')\n\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_df),len(test_df))\ntrain_df.head()","execution_count":10,"outputs":[{"output_type":"stream","text":"55095 12660\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   gameKey  playID     view                     video  frame label  impact  \\\n0    57584     336  Endzone  57584_000336_Endzone.mp4     29   V59     0.0   \n1    57584     336  Endzone  57584_000336_Endzone.mp4     29   V54     0.0   \n2    57584     336  Endzone  57584_000336_Endzone.mp4     29   V97     0.0   \n3    57584     336  Endzone  57584_000336_Endzone.mp4     29   V95     1.0   \n4    57584     336  Endzone  57584_000336_Endzone.mp4     29   H51     0.0   \n\n  impactType  confidence  visibility                          image_name    x  \\\n0          0         0.0         0.0  57584_000336_Endzone_029_V59_0.png  661   \n1          0         0.0         0.0  57584_000336_Endzone_029_V54_0.png  378   \n2          0         0.0         0.0  57584_000336_Endzone_029_V97_0.png  245   \n3          0         0.0         0.0  57584_000336_Endzone_029_V95_1.png  789   \n4          0         0.0         0.0  57584_000336_Endzone_029_H51_0.png  612   \n\n     y   w   h  \n0  143  22  36  \n1  146  22  34  \n2  243  24  32  \n3  242  24  35  \n4  227  30  24  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameKey</th>\n      <th>playID</th>\n      <th>view</th>\n      <th>video</th>\n      <th>frame</th>\n      <th>label</th>\n      <th>impact</th>\n      <th>impactType</th>\n      <th>confidence</th>\n      <th>visibility</th>\n      <th>image_name</th>\n      <th>x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57584</td>\n      <td>336</td>\n      <td>Endzone</td>\n      <td>57584_000336_Endzone.mp4</td>\n      <td>29</td>\n      <td>V59</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57584_000336_Endzone_029_V59_0.png</td>\n      <td>661</td>\n      <td>143</td>\n      <td>22</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57584</td>\n      <td>336</td>\n      <td>Endzone</td>\n      <td>57584_000336_Endzone.mp4</td>\n      <td>29</td>\n      <td>V54</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57584_000336_Endzone_029_V54_0.png</td>\n      <td>378</td>\n      <td>146</td>\n      <td>22</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57584</td>\n      <td>336</td>\n      <td>Endzone</td>\n      <td>57584_000336_Endzone.mp4</td>\n      <td>29</td>\n      <td>V97</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57584_000336_Endzone_029_V97_0.png</td>\n      <td>245</td>\n      <td>243</td>\n      <td>24</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57584</td>\n      <td>336</td>\n      <td>Endzone</td>\n      <td>57584_000336_Endzone.mp4</td>\n      <td>29</td>\n      <td>V95</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57584_000336_Endzone_029_V95_1.png</td>\n      <td>789</td>\n      <td>242</td>\n      <td>24</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57584</td>\n      <td>336</td>\n      <td>Endzone</td>\n      <td>57584_000336_Endzone.mp4</td>\n      <td>29</td>\n      <td>H51</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57584_000336_Endzone_029_H51_0.png</td>\n      <td>612</td>\n      <td>227</td>\n      <td>30</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDatasetBoxes(Dataset) :\n    def __init__(self, df=None, transform=None, img_size=(100,100), mask= False, input_folder=\"../input/resnet18-on-bboxes/\", name=\"train\") :\n        self.df = df\n        self.img_size = img_size\n        self.transform = transform\n        self.mask = mask\n        \n#         print(f\"name={name}\")\n        \n        if name == 'train':\n            self.input_folder = os.path.join(input_folder,'helmet_crop_train')\n        elif name == 'test':\n            self.input_folder = os.path.join(input_folder,'helmet_crop_test')\n            \n    def __len__(self) :\n        return len(self.df)\n    \n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        img_path = os.path.join(self.input_folder, row.image_name)\n        image = cv2.imread(img_path)\n    \n        if self.transform:\n            transformed_img = self.transform(image=image)['image']\n        \n        if int(row.impact) == 0:\n            label = torch.tensor([1.0,0.0])\n        elif int(row.impact) == 1:\n            label = torch.tensor([0.0,1.0])\n        else:\n            print(row.impact)\n            print(type(row.impact))\n            assert False, 'incorrect label type'\n        return transformed_img, label\n    ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Compose(\n    [\n        Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n        ),\n        ToTensor()\n    ]\n)\n\ntrain_dataset = ImageDatasetBoxes(train_df,transform= transform )\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\ntest_dataset = ImageDatasetBoxes(test_df,transform= transform, name = \"test\")\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training scrip"},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch_num = 7\n\ntrain_losses = []\ntest_losses = []\n# criterion = torch.nn.CrossEntropyLoss()\n\n\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_diff_net(model, model2):\n    for name, param in model.named_parameters():\n        for name2, param2 in model2.named_parameters():\n        #case load weight and non load weight\n            s = torch.tensor(0)\n            if(name==name2):\n#                 print(name)\n                temp = (param - param2).sum()\n                s = s + temp \n#                 print(temp)\n            break\n        break\n    \n    if(s == torch.tensor(0)):\n        print('same net')\n    else:\n        print('different net')\n        \n# check_diff_net(resnet18, t['model'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_from_epoch(model, start_epoch, epoch_num, model_name): \n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    train_losses = []\n    test_losses = []\n#     criterion = torch.nn.CrossEntropyLoss()\n    criterion = torch.nn.BCEWithLogitsLoss(weight = torch.tensor([1,5]).to(device))\n    \n#     assert start_epoch < epoch_num, 'start_epoch > epoch_num'\n    for e in range(start_epoch,epoch_num):\n        \n        sum_train = 0\n        sum_test = 0\n        train_count = 0\n        test_count = 0\n        for b, l in tqdm(train_loader) :\n            b = b.to(device)\n            l = l.to(device)\n\n            model.train()                        \n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n\n            out = model(b)\n\n            labels = l.argmax(1)\n#             train_loss = criterion(out, labels)\n            train_loss = criterion(out, l)\n            train_loss.backward()\n            optimizer.step()\n\n            with torch.set_grad_enabled(False):\n                sum_train += train_loss.to('cpu').item()\n                train_count += 1\n\n        model.eval()\n        with torch.no_grad():            \n            gts = []\n            preds = []\n    #     with torch.set_grad_enabled(False):\n            for b, l in tqdm(test_loader) :\n                b = b.to(device)\n                l = l.to(device)\n\n                out = model(b)\n                labels = l.argmax(1)\n                \n                out_ = out.argmax(1)\n                preds.append(out_.to('cpu').numpy())\n        \n                labels = l.argmax(1)\n                gts.append(labels.to('cpu').numpy())\n\n                test_loss = criterion(out, l)\n\n                sum_test += test_loss.to('cpu').item()\n                test_count += 1\n                \n            gts = np.concatenate(gts) \n            preds = np.concatenate(preds)\n            dic = {\n                'model': model,\n                'test_loss': test_loss.item(),\n                'training_loss': train_loss.item(),\n                'gts': gts,\n                'preds': preds,\n            }\n            print(classification_report(gts, preds))\n            print(confusion_matrix(gts, preds))\n            print(sum_train/train_count)\n            print(sum_test/test_count)\n            torch.save(dic, f\"{model_name}_epoch_no_mask{e}.pt\")\n            \n            train_losses.append(sum_train/train_count)\n            test_losses.append(sum_test/test_count)\n    return train_losses, test_losses","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = torch.load('resnet_epoch_no_mask0.pt')['model']\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel_name = 'se_resnext50_32x4d' # could be fbresnet152 or inceptionresnetv2\nmodel = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\nmodel.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\nmodel.last_linear = torch.nn.Linear(\n    model.last_linear.in_features,\n    2,\n)\nmodel = model.to(device)\ntrain_losses, test_losses = run_from_epoch(model, 0, 4, model_name)","execution_count":18,"outputs":[{"output_type":"stream","text":"Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=110559176.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfeac6565c2c47a4a39268d2a5922ec3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'device' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-ff077aa9e419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_from_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_losses = []\n# train_losses = []\n# for i in range(7):\n#     state =  torch.load(f\"./resnet_epoch_no_mask{i}.pt\")\n#     test_losses.append(state['test_loss'])\n#     train_losses.append(state['training_loss'])\n#     del state\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(range(epoch), train_losses, 'b')\nplt.plot(range(epoch), test_losses, 'r')\nplt.legend(['Train Losses','Test Losses'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('tét')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.rand(1,2)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = torch.load('resnet_epoch_no_mask4.pt')['model']\n\n# model.eval()\n# with torch.no_grad():            \n# #     with torch.set_grad_enabled(False):\n#     for b, l in tqdm(test_loader) :\n#         b = b.to(device)\n#         l = l.to(device)\n\n#         out = model(b)\n#         out_ = out.argmax(1)\n#         predicts.append(out_.to('cpu').numpy())\n        \n#         labels = l.argmax(1)\n#         gt.append(labels.to('cpu').numpy())\n#         test_loss = criterion(out, labels)\n\n#         sum_test += test_loss.to('cpu').item()\n        \n#         dic = {\n#             'model': model,\n#             'test_loss': test_loss.item(),\n#             'training_loss': train_loss.item()\n#         }\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.array(predicts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(classification_report(np.concatenate(gt), np.concatenate(predicts)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}